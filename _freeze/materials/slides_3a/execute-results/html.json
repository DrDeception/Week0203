{
  "hash": "c6e592b6dbbdd5a192ed29b9743697fc",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Intro to Data Visualisation II\"\nauthor: \"Dr. Gordon Wright\"\nengine: knitr\n\nformat: \n  revealjs: \n    slide-number: c/t\n    embed-resources: true\n    controls-layout: bottom-right\n    scrollable: true\n    code-overflow: wrap\n    code-line-numbers: true\n    code-copy: true\n    theme: [simple, slides.scss]\n    footer: \"Data Visualisation II\"\n  html: default\n# webr:\n#   packages: ['ggplot2', 'dplyr', 'tidyr'] # Install R packages on document open\n# # autoload-packages: false       # Disable automatic loading of packages\n# show-startup-message: false    # Disable displaying status of webR initialization\n# filters:\n# - webr\n---\n\n\n\n\n## Refresher/Primer on Data Types\n\nIn statistics, we work with various types of data. Understanding these types is crucial for:\n\n-   Choosing appropriate statistical methods\n-   Interpreting results correctly\n-   Making informed decisions based on data\n\nLet's explore the four main levels of measurement...\n\n::: notes\nEmphasize the importance of understanding data types for statistical analysis.\n:::\n\n## Nominal Data\n\n-   **Definition**: Categories or groups without intrinsic order\n-   **Characteristics**:\n    -   Cannot be ordered\n    -   No numerical value\n    -   Only shows distinct groups\n-   **Examples from our dataset**:\n    -   MBTI (Myers-Briggs Type Indicator)\n    -   Coin (Heads or Tails)\n    -   DogCatBoth (Preference for pets)\n\n::: notes\nExplain that nominal data is qualitative and used for labeling variables without any quantitative value.\n:::\n\n## Ordinal Data\n\n-   **Definition**: Categories with a meaningful order, but differences aren't measurable\n-   **Characteristics**:\n    -   Can be ordered\n    -   Intervals between ranks aren't necessarily equal\n-   **Examples from our dataset**:\n    -   1-7 rating scales (Likert scale responses)\n    -   TIPI scores (Big Five - OCEAN)\n\n::: notes\nHighlight that ordinal data has an order, but the distance between categories is not uniform or meaningful.\n:::\n\n## Interval Data\n\n-   **Definition**: Numerical data with consistent intervals, but no true zero point\n-   **Characteristics**:\n    -   Ordered with equal intervals between values\n    -   Can be added or subtracted\n    -   No true zero point\n-   **Examples**:\n    -   Temperature in Celsius or Fahrenheit\n    -   Calendar years\n\n::: notes\nExplain that interval data allows for degree of difference, but not ratio comparisons.\n:::\n\n## Ratio Data\n\n-   **Definition**: Numerical data with equal intervals and a true zero point\n-   **Characteristics**:\n    -   Ordered with equal intervals\n    -   Has a true zero point (absence of the variable is possible)\n    -   Can be added, subtracted, multiplied, and divided\n-   **Examples from our dataset**:\n    -   LoginCount\n    -   CompTime (assuming it's recorded in minutes)\n    -   EyeContact (assuming it's a continuous measure)\n\n::: notes\nEmphasize that ratio data allows for all arithmetic operations and comparisons.\n:::\n\n## Summary of Data Types\n\n| Data Type | Can Be Ordered? | Equal Intervals? | True Zero Point? | Example |\n|---------------|---------------|---------------|---------------|---------------|\n| Nominal | No | No | No | Gender, MBTI |\n| Ordinal | Yes | No | No | Scale measures, TIPI scores |\n| Interval | Yes | Yes | No | Temperature (°C) |\n| Ratio | Yes | Yes | Yes | LoginCount, CompTime |\n\n## Practical Application\n\nLet's look at some variables from our new, exciting dataset:\n\n| Column Name | Description | Data Type |\n|------------------------|------------------------|------------------------|\n| PokeNumber | Unique identifier for each Pokémon | Categorical |\n| PokeName | Name of the Pokémon | Text |\n| PokeImage | URL to the Pokémon's image | Text |\n| LoginCount | Number of VLE logins (to date) | Ratio |\n| Q_Scale | The Scale-Based Question you submitted for DS01 | Text |\n| Q_choice | The Choice-Based Question you submitted for DS01 | Text |\n| Q_option | The Open Question you submitted for DS01 | Text |\n| CompTime | DS02 Survey Completion Time | Ratio |\n| A-Level | Whether the participant has A-Levels | Categorical |\n| Coin | Result of a coin flip | Categorical |\n| EyeContact | Liking for Eye-Contact | Ordinal |\n| Psy4me | Is Psychology for me Question | Ordinal |\n| DrWho | Rating of Doctor Who | Ordinal |\n| Maths | Self-Assessed Maths competence | Ordinal |\n| InsectApocalypse | Preferred insect in case of an insect apocalypse | Categorical |\n| DogCatBoth | Preference for dogs, cats, or both | Categorical |\n| LarkorOwl | Preferred sleep/wake pattern | Categorical |\n| E_TIPI | Extraversion score from TIPI | Ordinal |\n| A_TIPI | Agreeableness score from TIPI | Ordinal |\n| C_TIPI | Conscientiousness score from TIPI | Ordinal |\n| ES_TIPI | Emotional Stability score from TIPI | Ordinal |\n| O_TIPI | Openness score from TIPI | Ordinal |\n| MBTI | Myers-Briggs Type Indicator result | Categorical |\n| Row | Lecture Hall Row Number F-B | Ordinal |\n| Column | Lecture Hall Column L-R | Ordinal |\n\n## Conclusion and Next Steps\n\n-   Understanding data types is crucial for proper statistical analysis\n-   In our dataset, we have a mix of nominal, ordinal, and ratio data\n-   Next, we'll explore how to summarize and visualize these different types of data\n\n## Introduction to Measures of Central Tendency\n\nMeasures of central tendency help us understand the typical or central value in a dataset. The three main measures are:\n\n1.  Mean\n2.  Median\n3.  Mode\n\nLet's explore each of these using our dataset...\n\n::: notes\nExplain that these measures help summarize data and provide a \"typical\" value.\n:::\n\n## Mean\n\n-   **Definition**: The average of all values in a dataset\n-   **Formula**: $\\bar{x} = \\frac{\\sum{X}}{N}$\n-   **Best for**: Interval and ratio data\n-   **Example**: Let's calculate the mean LoginCount\n\n## Let's see all the values available, first\n\nThis is called a Stem and Leaf Plot and we will calculate the mean below it.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Read the data\ndata <- read.csv(\"materials/data/Y1W3_data.csv\")\n\n# Create and print stem and leaf plot without showing NULL\ninvisible(stem(data$LoginCount, scale = 1))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  The decimal point is 1 digit(s) to the right of the |\n\n  0 | 112333444556668888999\n  1 | 000000000111122223333455555556677788899\n  2 | 00123333444456699\n  3 | 0023355567\n  4 | 34578\n  5 | 0168\n  6 | 1\n```\n\n\n:::\n\n```{.r .cell-code}\n# Calculate and print the mean\nmean_login <- mean(data$LoginCount, na.rm = TRUE)\ncat(\"\\nMean LoginCount:\", round(mean_login, 2))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nMean LoginCount: 19.43\n```\n\n\n:::\n:::\n\n\n\n\n## Median\n\n-   **Definition**: The middle value when data is ordered\n-   **Best for**: Ordinal, interval, and ratio data\n-   **Example**: Let's find the median LoginCount\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- read.csv(\"materials/data/Y1W3_data.csv\")\nmedian_login <- median(data$LoginCount, na.rm = TRUE)\ncat(\"Median LoginCount:\", median_login)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMedian LoginCount: 15\n```\n\n\n:::\n:::\n\n\n\n\n::: notes\nHighlight that the median is less affected by outliers than the mean.\n:::\n\n## Mode\n\n-   **Definition**: The most frequently occurring value\n-   **Best for**: Any type of data, especially nominal\n-   **Example**: Let's find the mode of DogCatBoth\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Read the data\ndata <- read.csv(\"materials/data/Y1W3_data.csv\")\n\n# Get frequency table\npet_counts <- table(data$DogCatBoth)\n\n# Sort the table in descending order\npet_counts_sorted <- sort(pet_counts, decreasing = TRUE)\n\n# Print the counts\ncat(\"Counts for DogCatBoth:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCounts for DogCatBoth:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(pet_counts_sorted)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCats Both Dogs \n  38   20   12 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Calculate and print the mode\nmode_pets <- names(pet_counts_sorted)[1]\ncat(\"\\nMode of DogCatBoth:\", mode_pets)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nMode of DogCatBoth: Cats\n```\n\n\n:::\n\n```{.r .cell-code}\n# Calculate the total number of responses\ntotal_responses <- sum(pet_counts)\n\n# Calculate and print the percentages\ncat(\"\\n\\nPercentages for DogCatBoth:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\nPercentages for DogCatBoth:\n```\n\n\n:::\n\n```{.r .cell-code}\npercentages <- (pet_counts_sorted / total_responses) * 100\nfor (pet in names(percentages)) {\n  cat(sprintf(\"%s: %.2f%%\\n\", pet, percentages[pet]))\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCats: 54.29%\nBoth: 28.57%\nDogs: 17.14%\n```\n\n\n:::\n:::\n\n\n\n\n::: notes\nExplain that mode is the only measure of central tendency for nominal data.\n:::\n\n## Comparing Measures of Central Tendency\n\nLet's compare these measures for LoginCount:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncat(\"Mean LoginCount:\", round(mean_login, 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean LoginCount: 19.43 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Median LoginCount:\", median_login, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMedian LoginCount: 15 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Mode LoginCount:\", as.numeric(names(sort(table(data$LoginCount), decreasing = TRUE)[1])))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMode LoginCount: 10\n```\n\n\n:::\n:::\n\n\n\n\n::: notes\nDiscuss what these differences might tell us about the distribution of LoginCount.\n:::\n\n## Introduction to Measures of Variance\n\nMeasures of variance help us understand the spread or dispersion of data. Key measures include:\n\n1.  Range\n2.  Interquartile Range (IQR)\n3.  Variance\n4.  Standard Deviation\n\n::: notes\nExplain that these measures complement central tendency by showing how spread out the data is.\n:::\n\n## Range and Interquartile Range (IQR)\n\n-   **Range**: Difference between the maximum and minimum values\n-   **IQR**: Range of the middle 50% of the data\n\nLet's calculate these for LoginCount:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlogin_range <- range(data$LoginCount, na.rm = TRUE)\nlogin_iqr <- IQR(data$LoginCount, na.rm = TRUE)\n\ncat(\"Range of LoginCount:\", login_range[2] - login_range[1], \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRange of LoginCount: 60 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"IQR of LoginCount:\", login_iqr)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nIQR of LoginCount: 15\n```\n\n\n:::\n:::\n\n\n\n\n::: notes\nExplain that range is sensitive to outliers, while IQR is more robust.\n:::\n\n## Variance and Standard Deviation\n\n-   **Variance**: Average squared deviation from the mean\n-   **Standard Deviation**: Square root of the variance\n\nLet's calculate these for LoginCount:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlogin_var <- var(data$LoginCount, na.rm = TRUE)\nlogin_sd <- sd(data$LoginCount, na.rm = TRUE)\n\ncat(\"Variance of LoginCount:\", round(login_var, 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nVariance of LoginCount: 191.44 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Standard Deviation of LoginCount:\", round(login_sd, 2))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nStandard Deviation of LoginCount: 13.84\n```\n\n\n:::\n:::\n\n\n\n\n::: notes\nExplain that standard deviation is in the same units as the original data, making it easier to interpret.\n:::\n\n## Interpreting Standard Deviation\n\n-   In a normal distribution:\n    -   About 68% of data falls within 1 SD of the mean\n    -   About 95% falls within 2 SD\n    -   About 99.7% falls within 3 SD\n\nLet's visualize this for LoginCount:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(dplyr)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'dplyr'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n```\n\n\n:::\n\n```{.r .cell-code}\n# Calculate mean and standard deviation\nmean_login <- mean(data$LoginCount, na.rm = TRUE)\nlogin_sd <- sd(data$LoginCount, na.rm = TRUE)\n\n# Create the plot\nggplot(data, aes(x = LoginCount)) +\n  geom_histogram(aes(y = ..density..), binwidth = 5, fill = \"skyblue\", color = \"black\", alpha = 0.7) +\n  geom_density(color = \"darkblue\", size = 1) +\n  geom_vline(xintercept = mean_login, color = \"red\", linetype = \"dashed\", size = 1) +\n  geom_vline(xintercept = mean_login + c(-1, 1) * login_sd, color = \"darkgreen\", linetype = \"dashed\", size = 1) +\n  geom_vline(xintercept = mean_login + c(-2, 2) * login_sd, color = \"blue\", linetype = \"dashed\", size = 1) +\n  annotate(\"text\", x = mean_login, y = 0.04, label = \"Mean\", color = \"red\", angle = 90, vjust = -0.5) +\n  annotate(\"text\", x = mean_login + login_sd, y = 0.04, label = \"68%\", color = \"darkgreen\", angle = 90, vjust = -0.5) +\n  annotate(\"text\", x = mean_login + 2*login_sd, y = 0.04, label = \"95%\", color = \"blue\", angle = 90, vjust = -0.5) +\n  labs(title = \"Distribution of LoginCount with Standard Deviations\",\n       subtitle = paste(\"Mean =\", round(mean_login, 2), \"SD =\", round(login_sd, 2)),\n       x = \"LoginCount\", \n       y = \"Density\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(density)` instead.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 12 rows containing non-finite outside the scale range\n(`stat_bin()`).\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 12 rows containing non-finite outside the scale range\n(`stat_density()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](slides_3a_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Calculate percentages within each SD range\nwithin_1sd <- mean(data$LoginCount >= (mean_login - login_sd) & data$LoginCount <= (mean_login + login_sd), na.rm = TRUE) * 100\nwithin_2sd <- mean(data$LoginCount >= (mean_login - 2*login_sd) & data$LoginCount <= (mean_login + 2*login_sd), na.rm = TRUE) * 100\nwithin_3sd <- mean(data$LoginCount >= (mean_login - 3*login_sd) & data$LoginCount <= (mean_login + 3*login_sd), na.rm = TRUE) * 100\n\ncat(\"Percentage within 1 SD:\", round(within_1sd, 2), \"%\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPercentage within 1 SD: 73.2 %\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Percentage within 2 SD:\", round(within_2sd, 2), \"%\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPercentage within 2 SD: 93.81 %\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Percentage within 3 SD:\", round(within_3sd, 2), \"%\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPercentage within 3 SD: 98.97 %\n```\n\n\n:::\n:::\n\n\n\n\n::: notes\nExplain how to interpret this visualization and what it tells us about the spread of LoginCount.\n:::\n\n## Application to Different Data Types\n\nLet's apply these concepts to different types of data in our dataset:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Read the original data\ndata <- read.csv(\"materials/data/Y1W3_data.csv\")\n\n# Create dummy data for Q_Scale\nset.seed(123)  # for reproducibility\nn <- nrow(data)\ndummy_q_scale <- sample(1:5, n, replace = TRUE, prob = c(0.1, 0.2, 0.4, 0.2, 0.1))\n\n# Add dummy Q_Scale to the data\ndata$Q_Scale <- dummy_q_scale\n\n# Analysis\n# For ratio data (LoginCount)\ncat(\"LoginCount (Ratio):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLoginCount (Ratio):\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Mean:\", round(mean(data$LoginCount, na.rm = TRUE), 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean: 19.43 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"SD:\", round(sd(data$LoginCount, na.rm = TRUE), 2), \"\\n\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSD: 13.84 \n```\n\n\n:::\n\n```{.r .cell-code}\n# For ordinal data (Q_Scale)\ncat(\"Q_Scale (Ordinal):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nQ_Scale (Ordinal):\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Mean:\", round(mean(data$Q_Scale, na.rm = TRUE), 2), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMean: 3.04 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Median:\", median(data$Q_Scale, na.rm = TRUE), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMedian: 3 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"IQR:\", IQR(data$Q_Scale, na.rm = TRUE), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nIQR: 2 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Frequency Table:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFrequency Table:\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(table(data$Q_Scale))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n 1  2  3  4  5 \n 9 25 40 23 12 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"\\n\")\n```\n\n```{.r .cell-code}\n# For nominal data (DogCatBoth)\ncat(\"DogCatBoth (Nominal):\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDogCatBoth (Nominal):\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(table(data$DogCatBoth))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nBoth Cats Dogs \n  20   38   12 \n```\n\n\n:::\n:::\n\n\n\n\n::: notes\nDiscuss how the choice of measure depends on the type of data, and how to interpret these results.\n:::\n\n## Mi-Fin\n\n-   Measures of central tendency and variance provide crucial summaries of our data\n-   The choice of measure depends on the type of data and the shape of its distribution\n-   These measures form the basis for more advanced statistical analyses\n-   In the second half, we'll explore how to visualize these concepts and dive deeper into our dataset and preview the labs!\n\n::: notes\nSummarize the key points about central tendency and variance, and preview the next part on data visualization.\n:::\n\n## Data Exploration\n\nData exploration involves:\n\n-   Visualizing data distributions\n-   Identifying patterns and relationships\n-   Detecting outliers and anomalies\n\nWe'll use various chart types to explore our dataset.\n\n::: notes\nExplain the importance of data exploration in understanding the dataset before applying more advanced statistical techniques.\n:::\n\n## Histogram: Login Count Distribution\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(dplyr)\n\n# Read the data\ndata <- read.csv(\"materials/data/Y1W3_data.csv\")\n\n# Create the ggplot object\np <- ggplot(data, aes(x = LoginCount)) +\n  geom_histogram(binwidth = 5, fill = \"skyblue\", color = \"black\", aes(text = paste(\"Login Count:\", ..x.., \"<br>Frequency:\", ..count..))) +\n  labs(title = \"Distribution of Login Counts - What do you think?\",\n       x = \"Login Count\",\n       y = \"Frequency\") +\n  theme_minimal()\n\n# Convert to plotly\ninteractive_plot <- ggplotly(p, tooltip = \"text\")\n\n# Configure the layout for better interactivity\ninteractive_plot <- interactive_plot %>% \n  layout(hoverlabel = list(bgcolor = \"white\"),\n         dragmode = \"zoom\")\n\n# If you're knitting to an HTML document or using in RStudio, you can display the plot with:\n# interactive_plot\n\n# For use in a reveal.js slideshow, you'll need to save this as an HTML file:\nhtmlwidgets::saveWidget(interactive_plot, \"login_count_distribution.html\")\n\n# Print a message about where the file is saved\ncat(\"Interactive plot saved as 'login_count_distribution.html' in your working directory.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nInteractive plot saved as 'login_count_distribution.html' in your working directory.\n```\n\n\n:::\n:::\n\n\n\n\n::: notes\nDiscuss the shape of the distribution, any skewness, and what it tells us about student engagement.\n:::\n\n## Bar Chart: Pet Preferences\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data, aes(x = DogCatBoth)) +\n  geom_bar(fill = \"lightgreen\") +\n  labs(title = \"Preference for Dogs, Cats, or Both\",\n       x = \"Preference\",\n       y = \"Count\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](slides_3a_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\n\n::: notes\nInterpret the bar chart, discussing the most common preference and potential implications for student engagement strategies.\n:::\n\n## Scatter Plot: Eye Contact vs Login Count\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data, aes(x = LoginCount, y = EyeContact)) +\n  geom_point(alpha = 0.7) +\n  labs(title = \"Eye Contact Score vs Login Count\",\n       x = \"Login Count\",\n       y = \"Eye Contact Score\") +\n  theme_minimal()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 39 rows containing missing values or values outside the scale range\n(`geom_point()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](slides_3a_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\n\n::: notes\nDiscuss any visible patterns or correlations, and what they might imply about the relationship between online engagement and social comfort.\n:::\n\n## Box Plot: Completion Time by Conscientiousness\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Read the data\ndata <- read.csv(\"materials/data/Y1W3_data.csv\")\n\n# Function to convert time string to minutes\ntime_to_minutes <- function(time_str) {\n  if (is.na(time_str) || time_str == \"\") return(NA)\n  parts <- strsplit(time_str, \":\")[[1]]\n  return(as.numeric(parts[1]) + as.numeric(parts[2]) / 60)\n}\n\n# Convert CompTime to minutes\ndata$CompTimeMinutes <- sapply(data$CompTime, time_to_minutes)\n\n# Remove NA values\ndata <- data %>% filter(!is.na(C_TIPI) & !is.na(CompTimeMinutes))\n\n# Perform median split on C_TIPI\nmedian_c <- median(data$C_TIPI, na.rm = TRUE)\ndata$C_Group <- factor(ifelse(data$C_TIPI > median_c, \"High\", \"Low\"), levels = c(\"Low\", \"High\"))\n\n# Verify the levels of C_Group\nprint(table(data$C_Group))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n Low High \n  61    9 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Create the plot\np <- ggplot(data, aes(x = C_Group, y = CompTimeMinutes)) +\n  geom_boxplot(fill = \"skyblue\", color = \"darkblue\") +\n  labs(title = \"Completion Time by Conscientiousness Level\",\n       x = \"Conscientiousness Level\",\n       y = \"Completion Time (hours)\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5))\n\n# Display the plot\nprint(p)\n```\n\n::: {.cell-output-display}\n![](slides_3a_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Calculate and display summary statistics\nsummary_stats <- data %>%\n  group_by(C_Group) %>%\n  summarise(\n    N = n(),\n    Mean = mean(CompTimeMinutes, na.rm = TRUE),\n    Median = median(CompTimeMinutes, na.rm = TRUE),\n    SD = sd(CompTimeMinutes, na.rm = TRUE)\n  )\n\n\n\n# # Additional diagnostic information\n# cat(\"\\nRange of C_TIPI scores:\", range(data$C_TIPI, na.rm = TRUE), \"\\n\")\n# cat(\"Median C_TIPI score:\", median_c, \"\\n\")\n# cat(\"Range of CompTimeMinutes:\", range(data$CompTimeMinutes, na.rm = TRUE), \"\\n\")\n```\n:::\n\n\n\n\n## Outliers removed\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Read the data\ndata <- read.csv(\"materials/data/Y1W3_data.csv\")\n\n# Function to convert time string to minutes\ntime_to_minutes <- function(time_str) {\n  if (is.na(time_str) || time_str == \"\") return(NA)\n  parts <- strsplit(time_str, \":\")[[1]]\n  return(as.numeric(parts[1]) + as.numeric(parts[2]) / 60)\n}\n\n# Convert CompTime to minutes\ndata$CompTimeMinutes <- sapply(data$CompTime, time_to_minutes)\n\n# Remove NA values and filter to 1 minute or less\ndata <- data %>% \n  filter(!is.na(C_TIPI) & !is.na(CompTimeMinutes) & CompTimeMinutes <= 1)\n\n# Perform median split on C_TIPI\nmedian_c <- median(data$C_TIPI, na.rm = TRUE)\ndata$C_Group <- factor(ifelse(data$C_TIPI > median_c, \"High\", \"Low\"), levels = c(\"Low\", \"High\"))\n\n# Remove outliers (values beyond 1.5 * IQR)\nQ1 <- quantile(data$CompTimeMinutes, 0.25)\nQ3 <- quantile(data$CompTimeMinutes, 0.75)\nIQR <- Q3 - Q1\ndata <- data %>% filter(CompTimeMinutes >= (Q1 - 1.5 * IQR) & CompTimeMinutes <= (Q3 + 1.5 * IQR))\n\n# Verify the levels of C_Group\nprint(table(data$C_Group))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n Low High \n  27   30 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Create the plot\np <- ggplot(data, aes(x = C_Group, y = CompTimeMinutes)) +\n  geom_boxplot(fill = \"skyblue\", color = \"darkblue\") +\n  labs(title = \"Completion Time by Conscientiousness Level\",\n       subtitle = \"Filtered to ≤ 1 hour and outliers removed\",\n       x = \"Conscientiousness Level\",\n       y = \"Completion Time (hours)\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5))\n\n# Display the plot\nprint(p)\n```\n\n::: {.cell-output-display}\n![](slides_3a_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Calculate and display summary statistics\nsummary_stats <- data %>%\n  group_by(C_Group) %>%\n  summarise(\n    N = n(),\n    Mean = mean(CompTimeMinutes, na.rm = TRUE),\n    Median = median(CompTimeMinutes, na.rm = TRUE),\n    SD = sd(CompTimeMinutes, na.rm = TRUE)\n  )\n\n\n# # Additional diagnostic information\n# cat(\"\\nRange of C_TIPI scores:\", range(data$C_TIPI, na.rm = TRUE), \"\\n\")\n# cat(\"Median C_TIPI score:\", median_c, \"\\n\")\n# cat(\"Range of CompTimeMinutes:\", range(data$CompTimeMinutes, na.rm = TRUE), \"\\n\")\n```\n:::\n\n\n\n\n::: notes\nInterpret the box plot, discussing differences in completion time between high and low conscientiousness groups.\n:::\n\n::: notes\nExplain how to interpret the radar chart and discuss the overall personality profile of the class based on TIPI scores.\n:::\n\n## MBTI Distribution\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmbti_data <- data %>%\n  filter(!is.na(MBTI)) %>%\n  count(MBTI) %>%\n  arrange(desc(n))\n\nggplot(mbti_data, aes(x = reorder(MBTI, -n), y = n)) +\n  geom_bar(stat = \"identity\", fill = \"coral\") +\n  labs(title = \"Distribution of MBTI Types\",\n       x = \"MBTI Type\",\n       y = \"Count\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](slides_3a_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n\n\n## Violin Plot: EyeContact by MBTI Extraversion/Introversion\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Read the data (if not already in the environment)\ndata <- read.csv(\"materials/data/Y1W3_data.csv\")\n\n# Extract E/I and filter for only E and I\ndata$IE <- substr(data$MBTI, 1, 1)\ndata_filtered <- data %>% \n  filter(IE %in% c(\"E\", \"I\"))\n\n# Create the plot\nggplot(data_filtered, aes(x = IE, y = EyeContact, fill = IE)) +\n  geom_violin(trim = FALSE) +\n  geom_boxplot(width = 0.1, fill = \"white\") +\n  labs(title = \"EyeContact Score by Extraversion/Introversion\",\n       x = \"MBTI Extraversion/Introversion\",\n       y = \"EyeContact Score\") +\n  scale_fill_manual(values = c(\"E\" = \"#FFA500\", \"I\" = \"#4682B4\")) +  # Orange for E, Steel Blue for I\n  theme_minimal() +\n  theme(legend.position = \"none\")  # Remove legend as it's redundant\n```\n\n::: {.cell-output-display}\n![](slides_3a_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Print summary statistics\nsummary_stats <- data_filtered %>%\n  group_by(IE) %>%\n  summarise(\n    n = n(),\n    mean = mean(EyeContact, na.rm = TRUE),\n    median = median(EyeContact, na.rm = TRUE),\n    sd = sd(EyeContact, na.rm = TRUE)\n  )\n# print(summary_stats)\n\n# # Perform t-test\n# t_test_result <- t.test(EyeContact ~ IE, data = data_filtered)\n# print(t_test_result)\n```\n:::\n\n\n\n\n::: notes\nInterpret the violin plot, discussing differences in eye contact scores between extraverts and introverts.\n:::\n\n## Stacked Bar Chart: MBTI Types by Pet Preference\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmbti_pet <- data %>%\n  filter(!is.na(MBTI) & !is.na(DogCatBoth)) %>%\n  count(MBTI, DogCatBoth) %>%\n  group_by(MBTI) %>%\n  mutate(prop = n / sum(n))\n\nggplot(mbti_pet, aes(x = MBTI, y = prop, fill = DogCatBoth)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"MBTI Types by Pet Preference\",\n       x = \"MBTI Type\",\n       y = \"Proportion\",\n       fill = \"Pet Preference\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](slides_3a_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n\n\n## Anscombe's Quartet\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'data.table'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:dplyr':\n\n    between, first, last\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](slides_3a_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n\n\n## Datasuarus\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# install.packages(\"datasauRus\")\nlibrary(datasauRus)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Load the datasaurus_dozen dataset\ndata(datasaurus_dozen)\n\n# Create the plot\nggplot(datasaurus_dozen, aes(x = x, y = y, colour = dataset)) +\n  geom_point() +\n  theme_void() +\n  theme(legend.position = \"none\") +\n  facet_wrap(~dataset, ncol = 3) +\n  labs(title = \"The Datasaurus Dozen\")\n```\n\n::: {.cell-output-display}\n![](slides_3a_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Calculate summary statistics for each dataset\nsummary_stats <- datasaurus_dozen %>%\n  group_by(dataset) %>%\n  summarise(\n    mean_x = mean(x),\n    mean_y = mean(y),\n    sd_x = sd(x),\n    sd_y = sd(y),\n    correlation = cor(x, y)\n  )\n```\n:::\n\n\n\n\n## Summary DatasauRus Stats\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Print the summary statistics\nprint(summary_stats)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 13 × 6\n   dataset    mean_x mean_y  sd_x  sd_y correlation\n   <chr>       <dbl>  <dbl> <dbl> <dbl>       <dbl>\n 1 away         54.3   47.8  16.8  26.9     -0.0641\n 2 bullseye     54.3   47.8  16.8  26.9     -0.0686\n 3 circle       54.3   47.8  16.8  26.9     -0.0683\n 4 dino         54.3   47.8  16.8  26.9     -0.0645\n 5 dots         54.3   47.8  16.8  26.9     -0.0603\n 6 h_lines      54.3   47.8  16.8  26.9     -0.0617\n 7 high_lines   54.3   47.8  16.8  26.9     -0.0685\n 8 slant_down   54.3   47.8  16.8  26.9     -0.0690\n 9 slant_up     54.3   47.8  16.8  26.9     -0.0686\n10 star         54.3   47.8  16.8  26.9     -0.0630\n11 v_lines      54.3   47.8  16.8  26.9     -0.0694\n12 wide_lines   54.3   47.8  16.8  26.9     -0.0666\n13 x_shape      54.3   47.8  16.8  26.9     -0.0656\n```\n\n\n:::\n:::\n\n\n\n\n## **Plato’s Triad: The True, The Good, and The Beautiful**\n\nPlato believed in the intrinsic connection between **truth**, **goodness**, and **beauty** — a concept that has influenced Western thought for centuries.\n\nFor Plato, these three qualities are inseparable in the realm of **Forms**.\n\nThe **truth** is inherently **good**, and what is **good** is also inherently **beautiful**.\n\nThus, if something is **false**, it cannot be truly **beautiful** or **good**.\n\n## R Big Picture\n\n[Quarto Publishing System](https://quarto.org/)\n\n## What do you currently use?\n\n**How do you write your essays or lab reports?**\n\n-   Microsoft Word?\n\n-   Google Docs?\n\n-   Markdown?\n\n::: fragment\n**How do you currently play with numbers?**\n\n-   Excel?\n\n-   SPSS?\n\n-   R?\n\n-   Python?\n:::\n\n## What is Quarto?\n\nQuarto is an open-source scientific and technical publishing system [that allows you to combine text, images, code, plots, and tables in a fully-reproducible document.]{.fragment}\n\n<br>\n\n[Quarto has support for multiple languages including R, Python, Julia, and Observable.]{.fragment}\n\n<br>\n\n[It also works for a range of output formats such as PDFs, HTML documents, websites, presentations,...]{.fragment}\n\n## Why use Quarto? Why use R?\n\n-   More journals require code to be submitted (for transparency and reproducibility). Keeping the code with the paper makes this easier.\n\n-   Copying and pasting is tedious (and a great source of accidental errors).\n\n-   If you fix an error in code or data, the results and figures in the paper update automatically.\n\n-   Easy to share publicly.\n\n-   Open source so anyone can use it.\n\n## What about R Markdown?\n\nR Markdown isn't going anywhere but...\n\n-   Quarto has better multi-language support\n\n-   More user-friendly\n\n-   Better control of the output layouts\n\n## Rendering a document\n\nWithin RStudio IDE: click **Render** (or Ctrl+Shift+K)\n\n. . .\n\nContent\n\n-   Text, links, images\n\n-   Code, tables, plots\n\n-   Equations, references\n\n## Output types\n\n::: incremental\n-   Documents: HTML, PDF, MS Word, Markdown\n\n-   Presentations: Revealjs, PowerPoint, Beamer\n\n-   Websites\n\n-   Books\n\n-   ...\n:::\n\n## Introduction\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n✔ readr     2.1.5     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ data.table::between() masks dplyr::between()\n✖ plotly::filter()      masks dplyr::filter(), stats::filter()\n✖ data.table::first()   masks dplyr::first()\n✖ lubridate::hour()     masks data.table::hour()\n✖ lubridate::isoweek()  masks data.table::isoweek()\n✖ dplyr::lag()          masks stats::lag()\n✖ data.table::last()    masks dplyr::last()\n✖ lubridate::mday()     masks data.table::mday()\n✖ lubridate::minute()   masks data.table::minute()\n✖ lubridate::month()    masks data.table::month()\n✖ lubridate::quarter()  masks data.table::quarter()\n✖ lubridate::second()   masks data.table::second()\n✖ purrr::transpose()    masks data.table::transpose()\n✖ lubridate::wday()     masks data.table::wday()\n✖ lubridate::week()     masks data.table::week()\n✖ lubridate::yday()     masks data.table::yday()\n✖ lubridate::year()     masks data.table::year()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(plotly)\nlibrary(knitr)\n\n# Load and prepare the data\ndata <- read_csv(\"materials/data/Y1W3_data.csv\", na = c(\"\", \"NA\", \"#N/A\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 109 Columns: 27\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (13): PokeName, PokeImage, Q_Scale, Q_choice, Q_option, A-Level, Coin, ...\ndbl  (13): PokeNumber, LoginCount, EyeContact, Psy4me, DrWho, Maths, E_TIPI,...\ntime  (1): CompTime\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nstudent_data <- data %>%\n  select(PokeNumber, PokeName, PokeImage, LoginCount, Q_Scale, CompTime, Image) %>%\n  mutate(\n    HasLoginCount = !is.na(LoginCount) & LoginCount != 0,\n    SubmittedQuestions = !is.na(CompTime) & CompTime != \"0\" & CompTime != \"\",\n    SubmittedImage = !is.na(Image) & Image != \"\"\n  )\n\n# Calculate engagement statistics\ntotal_students <- nrow(student_data)\nactive_students <- sum(student_data$HasLoginCount)\nquestions_submitted <- sum(student_data$SubmittedQuestions)\nimage_submitted <- sum(student_data$SubmittedImage)\n\n# Create a data frame for the engagement stages\nengagement_data <- data.frame(\n  Stage = c(\"Total Enrolled\", \"Active (Non-zero LoginCount)\", \"Submitted Questions\", \"Submitted Image\"),\n  Count = c(total_students, active_students, questions_submitted, image_submitted)\n)\n\n# Calculate percentages\nengagement_data$Percentage <- engagement_data$Count / total_students * 100\n\n# Reorder the stages to be in descending order\nengagement_data <- engagement_data %>%\n  arrange(desc(Count))\n\n# Display the engagement data\nkable(engagement_data, caption = \"Student Engagement Summary\", digits = 2)\n```\n\n::: {.cell-output-display}\n\n\nTable: Student Engagement Summary\n\n|Stage                        | Count| Percentage|\n|:----------------------------|-----:|----------:|\n|Total Enrolled               |   109|     100.00|\n|Active (Non-zero LoginCount) |    97|      88.99|\n|Submitted Questions          |    68|      62.39|\n|Submitted Image              |    41|      37.61|\n\n\n:::\n:::\n\n\n\n\n## Visual\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create a visual representation of the engagement\np <- plot_ly(engagement_data, x = ~reorder(Stage, -Count), y = ~Count, type = 'bar', \n             text = ~paste(Count, \" (\", round(Percentage, 1), \"%)\"), \n             textposition = 'auto',\n             marker = list(color = c('#1f77b4', '#2ca02c', '#d62728', '#9467bd'))) %>%\n  layout(title = \"Student Engagement Stages\",\n         xaxis = list(title = \"Stage\"),\n         yaxis = list(title = \"Number of Students\"),\n         showlegend = FALSE)\n\n# Display the plot\np\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"plotly html-widget html-fill-item\" id=\"htmlwidget-8ddcdfc64296f5794e54\" style=\"width:100%;height:464px;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-8ddcdfc64296f5794e54\">{\"x\":{\"visdat\":{\"895a64b404ff\":[\"function () \",\"plotlyVisDat\"]},\"cur_data\":\"895a64b404ff\",\"attrs\":{\"895a64b404ff\":{\"x\":{},\"y\":{},\"text\":{},\"textposition\":\"auto\",\"marker\":{\"color\":[\"#1f77b4\",\"#2ca02c\",\"#d62728\",\"#9467bd\"]},\"alpha_stroke\":1,\"sizes\":[10,100],\"spans\":[1,20],\"type\":\"bar\"}},\"layout\":{\"margin\":{\"b\":40,\"l\":60,\"t\":25,\"r\":10},\"title\":\"Student Engagement Stages\",\"xaxis\":{\"domain\":[0,1],\"automargin\":true,\"title\":\"Stage\",\"type\":\"category\",\"categoryorder\":\"array\",\"categoryarray\":[\"Total Enrolled\",\"Active (Non-zero LoginCount)\",\"Submitted Questions\",\"Submitted Image\"]},\"yaxis\":{\"domain\":[0,1],\"automargin\":true,\"title\":\"Number of Students\"},\"showlegend\":false,\"hovermode\":\"closest\"},\"source\":\"A\",\"config\":{\"modeBarButtonsToAdd\":[\"hoverclosest\",\"hovercompare\"],\"showSendToCloud\":false},\"data\":[{\"x\":[\"Total Enrolled\",\"Active (Non-zero LoginCount)\",\"Submitted Questions\",\"Submitted Image\"],\"y\":[109,97,68,41],\"text\":[\"109  ( 100 %)\",\"97  ( 89 %)\",\"68  ( 62.4 %)\",\"41  ( 37.6 %)\"],\"textposition\":[\"auto\",\"auto\",\"auto\",\"auto\"],\"marker\":{\"color\":[\"#1f77b4\",\"#2ca02c\",\"#d62728\",\"#9467bd\"],\"line\":{\"color\":\"rgba(31,119,180,1)\"}},\"type\":\"bar\",\"error_y\":{\"color\":\"rgba(31,119,180,1)\"},\"error_x\":{\"color\":\"rgba(31,119,180,1)\"},\"xaxis\":\"x\",\"yaxis\":\"y\",\"frame\":null}],\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.20000000000000001,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n\n\n## Visualisation of Your Data\n\nThis analysis covers levels of measurement, measures of central tendency, variance, and various plot types using the student data collected.\n\n## 1. Levels of Measurement\n\n1.  **Nominal**:\n    -   MBTI (Myers-Briggs Type Indicator)\n    -   Coin (Heads or Tails)\n    -   DogCatBoth (Preference for pets)\n    -   InsectApocalypse preference\n2.  **Ordinal**:\n    -   EyeContact (Likert or scale responses)\n    -   Ten Item Personality Inventory scores (OCEAN)\n3.  **Interval/Ratio**:\n    -   Count of VLE Logins so far \\[LoginCount\\]\n    -   Survey Completion Time \\[CompTime - minutes\\]\n\n## 2. Central Tendency and Variance\n\nLet's calculate these for LoginCount and the Extraversion (TIPI) score:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnumeric_data <- data %>%\n  select(LoginCount, E_TIPI) %>%\n  na.omit()\n\nsummary_stats <- numeric_data %>%\n  summarise(across(everything(), list(\n    Mean = ~mean(., na.rm = TRUE),\n    Median = ~median(., na.rm = TRUE),\n    SD = ~sd(., na.rm = TRUE),\n    Variance = ~var(., na.rm = TRUE)\n  )))\n\nkable(t(summary_stats), digits = 2, caption = \"Summary Statistics\")\n```\n\n::: {.cell-output-display}\n\n\nTable: Summary Statistics\n\n|                    |       |\n|:-------------------|------:|\n|LoginCount_Mean     |  22.29|\n|LoginCount_Median   |  18.00|\n|LoginCount_SD       |  13.93|\n|LoginCount_Variance | 193.95|\n|E_TIPI_Mean         |   3.18|\n|E_TIPI_Median       |   3.00|\n|E_TIPI_SD           |   0.49|\n|E_TIPI_Variance     |   0.24|\n\n\n:::\n:::\n\n\n\n\n## Various Plot Types\n\n### 1. Histogram: LoginCount\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data, aes(x = LoginCount)) +\n  geom_histogram(binwidth = 5, fill = \"skyblue\", color = \"black\") +\n  labs(title = \"Distribution of Login Counts\",\n       x = \"Login Count\",\n       y = \"Frequency\") +\n  theme_minimal()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 12 rows containing non-finite outside the scale range\n(`stat_bin()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](slides_3a_files/figure-html/histogram-1.png){width=672}\n:::\n:::\n\n\n\n\n## 2. Bar Chart: DogCatBoth Preferences\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Libraries\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Assuming `data` is your dataset\nggplot(data %>% filter(!is.na(DogCatBoth)), aes(x = DogCatBoth)) +\n  geom_bar(fill = \"lightgreen\") +\n  geom_text(stat = \"count\", aes(label = ..count..), vjust = -0.5) +  # Adds count figures on top of bars\n  labs(title = \"Preference for Dogs, Cats, or Both\",\n       x = \"Preference\",\n       y = \"Count\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](slides_3a_files/figure-html/bar-chart-1.png){width=672}\n:::\n:::\n\n\n\n\n## 3a. Insect Apocalypse\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(ggplot2)\n\ndata <- read_csv(\"materials/data/Y1W3_data.csv\")\n\n# Prepare the data\nbig_five_data <- data %>%\n  select(InsectApocalypse, E_TIPI, A_TIPI, C_TIPI, ES_TIPI, O_TIPI) %>%\n  pivot_longer(cols = c(E_TIPI, A_TIPI, C_TIPI, ES_TIPI, O_TIPI), \n               names_to = \"Trait\", \n               values_to = \"Score\") %>%\n  mutate(Trait = factor(Trait, \n                        levels = c(\"E_TIPI\", \"A_TIPI\", \"C_TIPI\", \"ES_TIPI\", \"O_TIPI\"),\n                        labels = c(\"Extraversion\", \"Agreeableness\", \"Conscientiousness\", \n                                   \"Emotional Stability\", \"Openness\"))) %>%\n  group_by(InsectApocalypse, Trait) %>%\n  summarise(Mean_Score = mean(Score, na.rm = TRUE), .groups = 'drop')\n\n# Create the plot\nggplot(big_five_data, aes(x = Trait, y = Mean_Score, fill = InsectApocalypse)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Big Five Personality Traits Across InsectApocalypse Groups\",\n       x = NULL, \n       y = \"Mean TIPI Score\",\n       fill = \"Insect Preference\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        legend.position = \"bottom\") +\n  scale_fill_brewer(palette = \"Set2\")\n```\n\n::: {.cell-output-display}\n![](slides_3a_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n\n\n## 3b. Insect Apocalypse\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(ggplot2)\n\n# Prepare the data\nbig_five_data <- data %>%\n  select(InsectApocalypse, E_TIPI, A_TIPI, C_TIPI, ES_TIPI, O_TIPI) %>%\n  pivot_longer(cols = c(E_TIPI, A_TIPI, C_TIPI, ES_TIPI, O_TIPI), \n               names_to = \"Trait\", \n               values_to = \"Score\") %>%\n  mutate(Trait = factor(Trait, \n                        levels = c(\"E_TIPI\", \"A_TIPI\", \"C_TIPI\", \"ES_TIPI\", \"O_TIPI\"),\n                        labels = c(\"Extraversion\", \"Agreeableness\", \"Conscientiousness\", \n                                   \"Emotional Stability\", \"Openness\"))) %>%\n  group_by(InsectApocalypse, Trait) %>%\n  summarise(\n    Mean_Score = mean(Score, na.rm = TRUE),\n    SE = sd(Score, na.rm = TRUE) / sqrt(n()),\n    .groups = 'drop'\n  )\n\n# Create the plot\nggplot(big_five_data, aes(x = Trait, y = Mean_Score, fill = InsectApocalypse)) +\n  geom_bar(stat = \"identity\", position = position_dodge(width = 0.9)) +\n  geom_errorbar(aes(ymin = Mean_Score - SE, ymax = Mean_Score + SE),\n                position = position_dodge(width = 0.9),\n                width = 0.25) +\n  labs(title = \"Big Five Personality Traits Across InsectApocalypse Groups\",\n       x = NULL, \n       y = \"Mean TIPI Score\",\n       fill = \"Insect Preference\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        legend.position = \"bottom\") +\n  scale_fill_brewer(palette = \"Set2\")\n```\n\n::: {.cell-output-display}\n![](slides_3a_files/figure-html/unnamed-chunk-23-1.png){width=1152}\n:::\n:::\n\n\n\n\n## 4a. Scatter Plot: EyeContact vs LoginCount\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data, aes(x = LoginCount, y = EyeContact)) +\n  geom_point(alpha = 0.7) +\n  labs(title = \"Eye Contact Score vs Login Count\",\n       x = \"Login Count\",\n       y = \"Eye Contact Score\") +\n  theme_minimal()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 39 rows containing missing values or values outside the scale range\n(`geom_point()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](slides_3a_files/figure-html/scatter-plot-1.png){width=672}\n:::\n:::\n\n\n\n\n## 4b. Scatter Plot: EyeContact vs LoginCount\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Libraries\nlibrary(ggplot2)\n\n# Assuming `data` is your dataset\nggplot(data, aes(x = LoginCount, y = EyeContact)) +\n  geom_point(alpha = 0.7) +\n  geom_smooth(method = \"lm\", color = \"blue\", se = FALSE) +  # Adds a trend line\n  labs(title = \"Eye Contact Score vs Login Count\",\n       x = \"Login Count\",\n       y = \"Eye Contact Score\") +\n  theme_minimal()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 39 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 39 rows containing missing values or values outside the scale range\n(`geom_point()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](slides_3a_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\n\n\n## 5a. Box Plot: CompTime by Conscientiousness Level\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create high/low conscientiousness groups\ndata$C_Group <- ifelse(data$C_TIPI > median(data$C_TIPI, na.rm = TRUE), \"High\", \"Low\")\n\n# Ensure CompTime is numeric and remove NAs for plotting\nggplot(data %>% filter(!is.na(CompTime)), aes(x = C_Group, y = as.numeric(CompTime))) +\n  geom_boxplot() +\n  labs(title = \"Completion Time by Conscientiousness Level\",\n       x = \"Conscientiousness Level\",\n       y = \"Completion Time (minutes)\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](slides_3a_files/figure-html/boxplot-1.png){width=672}\n:::\n:::\n\n\n\n\n## 5b. Box Plot: CompTime by Conscientiousness Level\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create high/low conscientiousness groups\ndata$C_Group <- ifelse(data$C_TIPI > median(data$C_TIPI, na.rm = TRUE), \"High\", \"Low\")\n\n# Filter data to include only responses with CompTime less than 2500 and remove NAs\nggplot(data %>% filter(!is.na(CompTime) & as.numeric(CompTime) < 2500), aes(x = C_Group, y = as.numeric(CompTime))) +\n  geom_boxplot() +\n  labs(title = \"Completion Time by Conscientiousness Level (Restricted to < 2500 minutes)\",\n       x = \"Conscientiousness Level\",\n       y = \"Completion Time (minutes)\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](slides_3a_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\n\n\n## 6. MBTI Count Matrix\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Libraries\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Exclude NAs and count occurrences of each MBTI type\nmbti_counts <- data %>%\n  filter(!is.na(MBTI)) %>%  # Exclude NAs\n  group_by(MBTI) %>%\n  summarize(Count = n()) %>%\n  arrange(desc(Count))\n\n# Display the counts\nprint(mbti_counts)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 15 × 2\n   MBTI  Count\n   <chr> <int>\n 1 ISTJ     10\n 2 IIFJ      9\n 3 ISFJ      7\n 4 IIFP      6\n 5 ISTP      6\n 6 EIFP      5\n 7 ESTP      5\n 8 IITJ      4\n 9 EIFJ      3\n10 EITJ      3\n11 IITP      3\n12 EITP      2\n13 ESFJ      2\n14 ESTJ      2\n15 ISFP      2\n```\n\n\n:::\n\n```{.r .cell-code}\n# Plot the counts using ggplot2\nggplot(mbti_counts, aes(x = reorder(MBTI, -Count), y = Count)) +\n  geom_bar(stat = \"identity\", fill = \"#69b3a2\") +\n  labs(title = \"Counts of Each MBTI Type (Excluding NAs)\",\n       x = \"MBTI Type\",\n       y = \"Count\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](slides_3a_files/figure-html/mbti-matrix-1.png){width=672}\n:::\n:::\n\n\n\n\n## 7. TIPI Radar Charts by Pet Preference\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Libraries\nlibrary(dplyr)\nlibrary(fmsb)  # For radar charts\n\n# Function to create radar chart with custom color\ncreate_radar_chart <- function(data, title, color) {\n  # Prepare radar data with max and min values for scaling\n  radar_data <- rbind(\n    c(5, 5, 5, 5, 5),  # Max values\n    c(1, 1, 1, 1, 1),  # Min values\n    data\n  )\n  colnames(radar_data) <- c(\"Extraversion\", \"Agreeableness\", \"Conscientiousness\", \"Emotional Stability\", \"Openness\")\n  \n  # Create radar chart\n  radarchart(radar_data, \n             pcol = color,                # Line color\n             pfcol = adjustcolor(color, alpha.f = 0.5),  # Filled color\n             plwd = 2,                    # Line width\n             plty = 1,                    # Line type\n             cglcol = \"grey\",             # Grid color\n             cglty = 1,                   # Grid line type\n             axislabcol = \"grey\",         # Axis label color\n             caxislabels = seq(1, 5, 1),  # Axis label values\n             cglwd = 0.8,                 # Grid line width\n             vlcex = 0.8                  # Label size\n  )\n  title(title)  # Add chart title\n}\n\n# Prepare data for each group\ndog_people <- data %>% \n  filter(DogCatBoth == \"Dogs\") %>%\n  select(E_TIPI, A_TIPI, C_TIPI, ES_TIPI, O_TIPI) %>%\n  summarise(across(everything(), mean, na.rm = TRUE))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: There was 1 warning in `summarise()`.\nℹ In argument: `across(everything(), mean, na.rm = TRUE)`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n```\n\n\n:::\n\n```{.r .cell-code}\ncat_people <- data %>% \n  filter(DogCatBoth == \"Cats\") %>%\n  select(E_TIPI, A_TIPI, C_TIPI, ES_TIPI, O_TIPI) %>%\n  summarise(across(everything(), mean, na.rm = TRUE))\n\nboth_people <- data %>% \n  filter(DogCatBoth == \"Both\") %>%\n  select(E_TIPI, A_TIPI, C_TIPI, ES_TIPI, O_TIPI) %>%\n  summarise(across(everything(), mean, na.rm = TRUE))\n\n# Set up plotting area to have 3 plots side by side\npar(mfrow = c(1, 3))\n\n# Create radar charts with different colors\ncreate_radar_chart(dog_people, \"Dog People\", \"blue\")\ncreate_radar_chart(cat_people, \"Cat People\", \"red\")\ncreate_radar_chart(both_people, \"Dog & Cat People\", \"green\")\n```\n\n::: {.cell-output-display}\n![](slides_3a_files/figure-html/tipi-radar-charts-1.png){width=1440}\n:::\n:::\n\n\n\n\n## 8. Heatmaps for Seating Preferences and TIPI Traits\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Libraries\nlibrary(ggplot2)\nlibrary(gridExtra)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'gridExtra'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:dplyr':\n\n    combine\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(dplyr)\n\n# Prepare seating data\nseating_data <- data %>%\n  select(Row, Column, E_TIPI, A_TIPI, C_TIPI, ES_TIPI, O_TIPI) %>%\n  na.omit()\n\n# Function to create heatmap with flipped x-axis and smooth coloring for each trait\ncreate_heatmap <- function(data, trait, title, colors) {\n  ggplot(data, aes(x = Column, y = Row, fill = .data[[trait]])) +\n    geom_tile() +\n    scale_x_reverse() +  # Flip the x-axis\n    scale_fill_gradientn(colors = colors) +  # Use custom colors for smoother gradient\n    labs(title = title, x = \"Column\", y = \"Row\") +\n    theme_minimal() +\n    theme(plot.title = element_text(hjust = 0.5))\n}\n\n# Color palettes for each trait\ncolors_extraversion <- c(\"white\", \"lightblue\", \"blue\")\ncolors_agreeableness <- c(\"white\", \"lightgreen\", \"green\")\ncolors_conscientiousness <- c(\"white\", \"yellow\", \"orange\")\ncolors_emotional_stability <- c(\"white\", \"pink\", \"red\")\ncolors_openness <- c(\"white\", \"purple\", \"purple4\")\n\n# Create heatmaps for each trait with different color scales\nplots <- list(\n  create_heatmap(seating_data, \"E_TIPI\", \"Extraversion\", colors_extraversion),\n  create_heatmap(seating_data, \"A_TIPI\", \"Agreeableness\", colors_agreeableness),\n  create_heatmap(seating_data, \"C_TIPI\", \"Conscientiousness\", colors_conscientiousness),\n  create_heatmap(seating_data, \"ES_TIPI\", \"Emotional Stability\", colors_emotional_stability),\n  create_heatmap(seating_data, \"O_TIPI\", \"Openness\", colors_openness)\n)\n\n# Arrange plots in a grid\ngrid.arrange(grobs = plots, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](slides_3a_files/figure-html/seating-heatmaps-1.png){width=1440}\n:::\n\n```{.r .cell-code}\n# Scatter plot of seating distribution with flipped x-axis\nggplot(seating_data, aes(x = Column, y = Row)) +\n  geom_point(alpha = 0.5) +\n  scale_x_reverse() +  # Flip the x-axis\n  labs(title = \"Distribution of Seating Preferences\", x = \"Column\", y = \"Row\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](slides_3a_files/figure-html/seating-heatmaps-2.png){width=1440}\n:::\n:::\n\n\n\n\n## note: BoxPlot Basics\n\n![](images/boxplot.png){fig-align=\"center\"}\n\n## 9. Compact Boxplots: TIPI Traits\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntipi_data <- data %>%\n  select(E_TIPI, A_TIPI, C_TIPI, ES_TIPI, O_TIPI) %>%\n  pivot_longer(cols = everything(), names_to = \"Trait\", values_to = \"Score\") %>%\n  mutate(Trait = factor(Trait, levels = c(\"E_TIPI\", \"A_TIPI\", \"C_TIPI\", \"ES_TIPI\", \"O_TIPI\"),\n                        labels = c(\"Extraversion\", \"Agreeableness\", \"Conscientiousness\", \"Emotional Stability\", \"Openness\")))\n\nggplot(tipi_data, aes(x = Trait, y = Score, fill = Trait)) +\n  geom_boxplot() +\n  labs(title = \"Distribution of TIPI Traits\", x = \"\", y = \"Score\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        legend.position = \"none\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 195 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](slides_3a_files/figure-html/tipi-boxplots-1.png){width=960}\n:::\n:::\n\n\n\n\n## 10. Violin Plots: EyeContact and Psy4me by MBTI Dimension\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggExtra)\nlibrary(gridExtra)\nlibrary(ggplot2)  # Explicitly load ggplot2 for clarity\n\n# Filter and mutate data without pipes\nmbti_data <- subset(data, !is.na(MBTI))\nmbti_data$IE <- substr(mbti_data$MBTI, 1, 1)\nmbti_data$SN <- substr(mbti_data$MBTI, 2, 2)\nmbti_data$TF <- substr(mbti_data$MBTI, 3, 3)\nmbti_data$JP <- substr(mbti_data$MBTI, 4, 4)\n\n# Create the first plot\np1 <- ggplot(mbti_data, aes(x = IE, y = EyeContact, fill = IE)) +\n  geom_violin(trim = FALSE) +\n  geom_boxplot(width = 0.1, fill = \"white\") +\n  labs(title = \"EyeContact by I/E Preference\", x = \"\", y = \"EyeContact Score\") +\n  theme_minimal()\n\n# Create the second plot\np2 <- ggplot(mbti_data, aes(x = SN, y = Psy4me, fill = SN)) +\n  geom_violin(trim = FALSE) +\n  geom_boxplot(width = 0.1, fill = \"white\") +\n  labs(title = \"Psychology Interest by S/N Preference\", x = \"\", y = \"Psy4me Score\") +\n  theme_minimal()\n\n# Arrange the plots side by side\ngrid.arrange(p1, p2, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](slides_3a_files/figure-html/mbti-violin-plots-1.png){width=1152}\n:::\n:::\n\n\n\n\n## 11. Scatterplots: Exploring Relationships\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np3 <- ggplot(data, aes(x = E_TIPI, y = EyeContact, color = DogCatBoth)) +\n  geom_point(alpha = 0.6) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(title = \"Extraversion vs EyeContact\", x = \"Extraversion Score\", y = \"EyeContact Score\") +\n  theme_minimal()\n\np3\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 39 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Removed 39 rows containing missing values or values outside the scale range\n(`geom_point()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](slides_3a_files/figure-html/scatterplots-1.png){width=1152}\n:::\n:::",
    "supporting": [
      "slides_3a_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../site_libs/htmltools-fill-0.5.8.1/fill.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/htmlwidgets-1.6.4/htmlwidgets.js\"></script>\n<script src=\"../site_libs/plotly-binding-4.10.4/plotly.js\"></script>\n<script src=\"../site_libs/typedarray-0.1/typedarray.min.js\"></script>\n<script src=\"../site_libs/jquery-3.5.1/jquery.min.js\"></script>\n<link href=\"../site_libs/crosstalk-1.2.1/css/crosstalk.min.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/crosstalk-1.2.1/js/crosstalk.min.js\"></script>\n<link href=\"../site_libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/plotly-main-2.11.1/plotly-latest.min.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}