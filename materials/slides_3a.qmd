---
title: "Intro to Data Visualisation II"
author: "Dr. Gordon Wright"
engine: knitr

format: 
  revealjs: 
    slide-number: c/t
    controls-layout: bottom-right
    embed-resources: true
    scrollable: true
    code-overflow: wrap
    code-line-numbers: true
    code-copy: true
    theme: [simple, slides.scss]
    reference-location: document
    footer: "Data Visualisation II"
webr:
  packages: ['ggplot2', 'dplyr', 'tidyr'] # Install R packages on document open
# autoload-packages: false       # Disable automatic loading of packages
show-startup-message: false    # Disable displaying status of webR initialization
filters:
- webr
---

## Introduction to Data Types

In statistics, we work with various types of data. Understanding these types is crucial for:

-   Choosing appropriate statistical methods
-   Interpreting results correctly
-   Making informed decisions based on data

Let's explore the four main levels of measurement...

::: notes
Emphasize the importance of understanding data types for statistical analysis.
:::

## Nominal Data 

-   **Definition**: Categories or groups without intrinsic order
-   **Characteristics**:
    -   Cannot be ordered
    -   No numerical value
    -   Only shows distinct groups
-   **Examples from our dataset**:
    -   MBTI (Myers-Briggs Type Indicator)
    -   Coin (Heads or Tails)
    -   DogCatBoth (Preference for pets)

::: notes
Explain that nominal data is qualitative and used for labeling variables without any quantitative value.
:::

## Ordinal Data

-   **Definition**: Categories with a meaningful order, but differences aren't measurable
-   **Characteristics**:
    -   Can be ordered
    -   Intervals between ranks aren't necessarily equal
-   **Examples from our dataset**:
    -   1-7 rating scales (Likert scale responses)
    -   TIPI scores (Big Five - OCEAN)

::: notes
Highlight that ordinal data has an order, but the distance between categories is not uniform or meaningful.
:::

## Interval Data

-   **Definition**: Numerical data with consistent intervals, but no true zero point
-   **Characteristics**:
    -   Ordered with equal intervals between values
    -   Can be added or subtracted
    -   No true zero point
-   **Examples**:
    -   Temperature in Celsius or Fahrenheit
    -   Calendar years

::: notes
Explain that interval data allows for degree of difference, but not ratio comparisons.
:::

## Ratio Data

-   **Definition**: Numerical data with equal intervals and a true zero point
-   **Characteristics**:
    -   Ordered with equal intervals
    -   Has a true zero point (absence of the variable is possible)
    -   Can be added, subtracted, multiplied, and divided
-   **Examples from our dataset**:
    -   LoginCount
    -   CompTime (assuming it's recorded in minutes)
    -   EyeContact (assuming it's a continuous measure)

::: notes
Emphasize that ratio data allows for all arithmetic operations and comparisons.
:::

## Summary of Data Types

| Data Type | Can Be Ordered? | Equal Intervals? | True Zero Point? | Example |
|---------------|---------------|---------------|---------------|---------------|
| Nominal | No | No | No | Gender, MBTI |
| Ordinal | Yes | No | No | Scale measures, TIPI scores |
| Interval | Yes | Yes | No | Temperature (Â°C) |
| Ratio | Yes | Yes | Yes | LoginCount, CompTime |

::: notes
Review the key differences between the four levels of measurement.
:::

## Practical Application

Let's look at some variables from our dataset:

```{webr-r}
# Load data (assuming it's available in the webr environment)
data <- read.csv("materials/data/Y1W3_data.csv")

# Display column names and data types
str(data, give.attr = FALSE)
```

::: notes
Explain how to identify the data type of each variable and why it matters for analysis.
:::

## Conclusion and Next Steps

-   Understanding data types is crucial for proper statistical analysis
-   In our dataset, we have a mix of nominal, ordinal, and ratio data
-   Next, we'll explore how to summarize and visualize these different types of data

::: notes
Summarize the key points about data types and preview the next part of the lecture.
:::

## Introduction to Measures of Central Tendency

Measures of central tendency help us understand the typical or central value in a dataset. The three main measures are:

1.  Mean
2.  Median
3.  Mode

Let's explore each of these using our dataset...

::: notes
Explain that these measures help summarize data and provide a "typical" value.
:::

## Mean

-   **Definition**: The average of all values in a dataset
-   **Formula**: $\bar{x} = \frac{\sum{X}}{N}$
-   **Best for**: Interval and ratio data
-   **Example**: Let's calculate the mean LoginCount

```{webr-r}
data <- read.csv("Y1W3_data.csv")
mean_login <- mean(data$LoginCount, na.rm = TRUE)
cat("Mean LoginCount:", round(mean_login, 2))
```

::: notes
Explain that the mean is sensitive to outliers and works best with symmetric distributions.
:::

## Median

-   **Definition**: The middle value when data is ordered
-   **Best for**: Ordinal, interval, and ratio data
-   **Example**: Let's find the median LoginCount

```{webr-r}
median_login <- median(data$LoginCount, na.rm = TRUE)
cat("Median LoginCount:", median_login)
```

::: notes
Highlight that the median is less affected by outliers than the mean.
:::

## Mode

-   **Definition**: The most frequently occurring value
-   **Best for**: Any type of data, especially nominal
-   **Example**: Let's find the mode of DogCatBoth

```{webr-r}
mode_pets <- names(sort(table(data$DogCatBoth), decreasing = TRUE))[1]
cat("Mode of DogCatBoth:", mode_pets)
```

::: notes
Explain that mode is the only measure of central tendency for nominal data.
:::

## Comparing Measures of Central Tendency

Let's compare these measures for LoginCount:

```{webr-r}
cat("Mean LoginCount:", round(mean_login, 2), "\n")
cat("Median LoginCount:", median_login, "\n")
cat("Mode LoginCount:", as.numeric(names(sort(table(data$LoginCount), decreasing = TRUE)[1])))
```

::: notes
Discuss what these differences might tell us about the distribution of LoginCount.
:::

## Introduction to Measures of Variance

Measures of variance help us understand the spread or dispersion of data. Key measures include:

1.  Range
2.  Interquartile Range (IQR)
3.  Variance
4.  Standard Deviation

::: notes
Explain that these measures complement central tendency by showing how spread out the data is.
:::

## Range and Interquartile Range (IQR)

-   **Range**: Difference between the maximum and minimum values
-   **IQR**: Range of the middle 50% of the data

Let's calculate these for LoginCount:

```{webr-r}
login_range <- range(data$LoginCount, na.rm = TRUE)
login_iqr <- IQR(data$LoginCount, na.rm = TRUE)

cat("Range of LoginCount:", login_range[2] - login_range[1], "\n")
cat("IQR of LoginCount:", login_iqr)
```

::: notes
Explain that range is sensitive to outliers, while IQR is more robust.
:::

## Variance and Standard Deviation

-   **Variance**: Average squared deviation from the mean
-   **Standard Deviation**: Square root of the variance

Let's calculate these for LoginCount:

```{webr-r}
login_var <- var(data$LoginCount, na.rm = TRUE)
login_sd <- sd(data$LoginCount, na.rm = TRUE)

cat("Variance of LoginCount:", round(login_var, 2), "\n")
cat("Standard Deviation of LoginCount:", round(login_sd, 2))
```

::: notes
Explain that standard deviation is in the same units as the original data, making it easier to interpret.
:::

## Interpreting Standard Deviation

-   In a normal distribution:
    -   About 68% of data falls within 1 SD of the mean
    -   About 95% falls within 2 SD
    -   About 99.7% falls within 3 SD

Let's visualize this for LoginCount:

```{webr-r}
library(ggplot2)

ggplot(data, aes(x = LoginCount)) +
  geom_histogram(binwidth = 5, fill = "skyblue", color = "black") +
  geom_vline(xintercept = mean_login, color = "red", linetype = "dashed") +
  geom_vline(xintercept = mean_login + c(-1, 1) * login_sd, color = "green", linetype = "dashed") +
  geom_vline(xintercept = mean_login + c(-2, 2) * login_sd, color = "blue", linetype = "dashed") +
  labs(title = "Distribution of LoginCount with SD", x = "LoginCount", y = "Frequency") +
  theme_minimal()
```

::: notes
Explain how to interpret this visualization and what it tells us about the spread of LoginCount.
:::

## Application to Different Data Types

Let's apply these concepts to different types of data in our dataset:

```{webr-r}
# For ratio data (LoginCount)
cat("LoginCount (Ratio):\n")
cat("Mean:", round(mean(data$LoginCount, na.rm = TRUE), 2), "\n")
cat("SD:", round(sd(data$LoginCount, na.rm = TRUE), 2), "\n\n")

# For ordinal data (Q_Scale)
cat("Q_Scale (Ordinal):\n")
cat("Median:", median(data$Q_Scale, na.rm = TRUE), "\n")
cat("IQR:", IQR(data$Q_Scale, na.rm = TRUE), "\n\n")

# For nominal data (DogCatBoth)
cat("DogCatBoth (Nominal):\n")
print(table(data$DogCatBoth))
```

::: notes
Discuss how the choice of measure depends on the type of data, and how to interpret these results.
:::

## Conclusion and Next Steps

-   Measures of central tendency and variance provide crucial summaries of our data
-   The choice of measure depends on the type of data and the shape of its distribution
-   These measures form the basis for more advanced statistical analyses
-   Next, we'll explore how to visualize these concepts and dive deeper into our dataset

::: notes
Summarize the key points about central tendency and variance, and preview the next part on data visualization.
:::

## Introduction to Data Exploration

Data exploration involves:

-   Visualizing data distributions
-   Identifying patterns and relationships
-   Detecting outliers and anomalies

We'll use various chart types to explore our dataset.

::: notes
Explain the importance of data exploration in understanding the dataset before applying more advanced statistical techniques.
:::

## Histogram: Login Count Distribution

```{webr-r}
library(ggplot2)
library(dplyr)

data <- read.csv("Y1W3_data.csv")

ggplot(data, aes(x = LoginCount)) +
  geom_histogram(binwidth = 5, fill = "skyblue", color = "black") +
  labs(title = "Distribution of Login Counts",
       x = "Login Count",
       y = "Frequency") +
  theme_minimal()
```

::: notes
Discuss the shape of the distribution, any skewness, and what it tells us about student engagement.
:::

## Bar Chart: Pet Preferences

```{webr-r}
ggplot(data, aes(x = DogCatBoth)) +
  geom_bar(fill = "lightgreen") +
  labs(title = "Preference for Dogs, Cats, or Both",
       x = "Preference",
       y = "Count") +
  theme_minimal()
```

::: notes
Interpret the bar chart, discussing the most common preference and potential implications for student engagement strategies.
:::

## Scatter Plot: Eye Contact vs Login Count

```{webr-r}
ggplot(data, aes(x = LoginCount, y = EyeContact)) +
  geom_point(alpha = 0.7) +
  labs(title = "Eye Contact Score vs Login Count",
       x = "Login Count",
       y = "Eye Contact Score") +
  theme_minimal()
```

::: notes
Discuss any visible patterns or correlations, and what they might imply about the relationship between online engagement and social comfort.
:::

## Box Plot: Completion Time by Conscientiousness

```{webr-r}
data$C_Group <- ifelse(data$C_TIPI > median(data$C_TIPI, na.rm = TRUE), "High", "Low")

ggplot(data, aes(x = C_Group, y = as.numeric(as.period(hms(CompTime))) / 60)) +
  geom_boxplot() +
  labs(title = "Completion Time by Conscientiousness Level",
       x = "Conscientiousness Level",
       y = "Completion Time (minutes)") +
  theme_minimal()
```

::: notes
Interpret the box plot, discussing differences in completion time between high and low conscientiousness groups.
:::

## Radar Chart: TIPI Personality Traits

```{webr-r}
library(tidyr)

tipi_data <- data %>%
  select(E_TIPI, A_TIPI, C_TIPI, ES_TIPI, O_TIPI) %>%
  summarise(across(everything(), mean, na.rm = TRUE)) %>%
  pivot_longer(cols = everything(), names_to = "Trait", values_to = "Score")

ggplot(tipi_data, aes(x = Trait, y = Score, group = 1)) +
  geom_polygon(fill = "lightblue", alpha = 0.5) +
  geom_line() +
  geom_point() +
  coord_polar() +
  ylim(0, 5) +
  labs(title = "Average TIPI Scores") +
  theme_minimal()
```

::: notes
Explain how to interpret the radar chart and discuss the overall personality profile of the class based on TIPI scores.
:::

## MBTI Distribution

```{webr-r}
mbti_data <- data %>%
  filter(!is.na(MBTI)) %>%
  count(MBTI) %>%
  arrange(desc(n))

ggplot(mbti_data, aes(x = reorder(MBTI, -n), y = n)) +
  geom_bar(stat = "identity", fill = "coral") +
  labs(title = "Distribution of MBTI Types",
       x = "MBTI Type",
       y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

::: notes
Discuss the distribution of MBTI types in the class and potential implications for teaching strategies.
:::

## Correlation Heatmap: TIPI Traits

```{webr-r}
library(reshape2)

tipi_cor <- data %>%
  select(E_TIPI, A_TIPI, C_TIPI, ES_TIPI, O_TIPI) %>%
  cor(use = "pairwise.complete.obs")

tipi_cor_melted <- melt(tipi_cor)

ggplot(tipi_cor_melted, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0) +
  labs(title = "Correlation Heatmap of TIPI Traits") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

::: notes
Interpret the correlation heatmap, discussing which personality traits tend to be related and which are more independent.
:::

## Exploring Relationships: LoginCount and TIPI Traits

```{webr-r}
tipi_login_cor <- data %>%
  select(LoginCount, E_TIPI, A_TIPI, C_TIPI, ES_TIPI, O_TIPI) %>%
  cor(use = "pairwise.complete.obs")

tipi_login_cor_melted <- melt(tipi_login_cor)

ggplot(tipi_login_cor_melted, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0) +
  labs(title = "Correlation: LoginCount and TIPI Traits") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

::: notes
Discuss any notable correlations between login count and personality traits, and what this might imply about online engagement.
:::

## Violin Plot: EyeContact by MBTI Extraversion/Introversion

```{webr-r}
data$IE <- substr(data$MBTI, 1, 1)

ggplot(data, aes(x = IE, y = EyeContact, fill = IE)) +
  geom_violin(trim = FALSE) +
  geom_boxplot(width = 0.1, fill = "white") +
  labs(title = "EyeContact Score by Extraversion/Introversion",
       x = "MBTI Extraversion/Introversion",
       y = "EyeContact Score") +
  theme_minimal()
```

::: notes
Interpret the violin plot, discussing differences in eye contact scores between extraverts and introverts.
:::

## Stacked Bar Chart: MBTI Types by Pet Preference

```{webr-r}
mbti_pet <- data %>%
  filter(!is.na(MBTI) & !is.na(DogCatBoth)) %>%
  count(MBTI, DogCatBoth) %>%
  group_by(MBTI) %>%
  mutate(prop = n / sum(n))

ggplot(mbti_pet, aes(x = MBTI, y = prop, fill = DogCatBoth)) +
  geom_bar(stat = "identity") +
  labs(title = "MBTI Types by Pet Preference",
       x = "MBTI Type",
       y = "Proportion",
       fill = "Pet Preference") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

::: notes
Discuss any interesting patterns in pet preferences across MBTI types and potential implications for understanding student personalities.
:::

## Conclusion and Key Insights

-   Recap the main findings from our data exploration
-   Discuss how these insights can inform teaching strategies and student engagement
-   Highlight the importance of data-driven decision making in education

::: notes
Summarize the key takeaways from the data exploration and how they can be applied in the educational context.
:::

## Next Steps

-   Encourage further exploration of the dataset
-   Discuss potential research questions that could be investigated
-   Introduce more advanced statistical techniques for future analysis

::: notes
Provide direction for students to continue their statistical journey and apply these concepts to their own research interests.
:::

## **Platoâs Triad: The True, The Good, and The Beautiful**

Plato believed in the intrinsic connection between **truth**, **goodness**, and **beauty** â a concept that has influenced Western thought for centuries.

For Plato, these three qualities are inseparable in the realm of **Forms**.

The **truth** is inherently **good**, and what is **good** is also inherently **beautiful**.

Thus, if something is **false**, it cannot be truly **beautiful** or **good**.

## Financial Times

[Visual Vocabulary](https://ft-interactive.github.io/visual-vocabulary/) is a site for stuff \## Introduction

> "Far better an approximate answer to the right question, which is often vague, than an exact answer to the wrong question, which can always be made precise." ---John W. Tukey

-   Descriptive statistics are tools for describing data
-   There are many ways to describe data
-   Choose the most useful way for your data
-   Describing data is necessary because there's usually too much of it

------------------------------------------------------------------------

## Too Many Numbers

-   Example: Asking thousands of people about their happiness
-   Raw data is overwhelming and difficult to interpret

```{r}
#| echo: false
happiness <- rnorm(500, 100, 500)
knitr::kable(matrix(round(happiness), ncol=10, nrow=5))
```

------------------------------------------------------------------------

[From Data to Viz website](https://www.data-to-viz.com/)

[Quarto Publishing System](https://quarto.org/)

## What do you currently use?

**How do you write your essays or lab reports?**

-   Microsoft Word?

-   Google Docs?

-   Markdown?

::: fragment
**How do you currently play with numbers?**

-   Excel?

-   SPSS?

-   R?

-   Python?
:::

## What is Quarto?

Quarto is an open-source scientific and technical publishing system [that allows you to combine text, images, code, plots, and tables in a fully-reproducible document.]{.fragment}

<br>

[Quarto has support for multiple languages including R, Python, Julia, and Observable.]{.fragment}

<br>

[It also works for a range of output formats such as PDFs, HTML documents, websites, presentations,...]{.fragment}

## Why use Quarto? Why use R?

-   More journals require code to be submitted (for transparency and reproducibility). Keeping the code with the paper makes this easier.

-   Copying and pasting is tedious (and a great source of accidental errors).

-   If you fix an error in code or data, the results and figures in the paper update automatically.

-   Easy to share publicly.

-   Open source so anyone can use it.

## What about R Markdown?

R Markdown isn't going anywhere but...

-   Quarto has better multi-language support

-   More user-friendly

-   Better control of the output layouts

# Your first Quarto document {background-color="#D9DBDB"}

## Creating a document

<p style="text-align:center;">

<img src="images/new_doc.gif" alt="Gif of creating a new quarto document" width="50%"/>

</p>

## Quarto in RStudio

::::: columns
::: column
**Source editor**

![](images/source.png){fig-align="center" width="70%"}
:::

::: column
**Visual editor**

![](images/visual.png){fig-align="center" width="70%"}
:::
:::::

## Rendering a document

Within RStudio IDE: click **Render** (or Ctrl+Shift+K)

. . .

<br>

Using {quarto}

```{r}
#| eval: false
#| echo: true
library(quarto)
quarto_render("document.qmd")
```

. . .

<br>

Using the command line

``` bash
quarto render document.qmd
```

## What makes a Quarto document?

YAML header

``` yaml
---
title: "A very cool title"
format: html
---
```

. . .

Content

-   Text, links, images

-   Code, tables, plots

-   Equations, references

## Output types

::: incremental
-   Documents: HTML, PDF, MS Word, Markdown

-   Presentations: Revealjs, PowerPoint, Beamer

-   Websites

-   Books

-   ...
:::

## Looking at Data: Graphs

### Scatter Plot

```{r}
#| echo: false
plot(happiness)
```

------------------------------------------------------------------------

## Looking at Data: Histograms

```{r}
#| echo: false
hist(happiness)
```

-   Shows the distribution of data
-   Reveals shape, center, and spread

------------------------------------------------------------------------

## Important Ideas

1.  Distribution
2.  Central Tendency
3.  Variance

------------------------------------------------------------------------

## Measures of Central Tendency

1.  Mode
2.  Median
3.  Mean

------------------------------------------------------------------------

## Mode

-   Most frequently occurring number
-   Example: 1, 1, 1, 2, 3, 4, 5, 6
-   Mode = 1

------------------------------------------------------------------------

## Median

-   Middle value when data is ordered
-   Example: 1, 3, 4, **5**, 6, 7, 9
-   Median = 5

------------------------------------------------------------------------

## Mean

$Mean = \bar{X} = \frac{\sum_{i=1}^{n} x_{i}}{N}$

-   Sum of all values divided by the number of values
-   Represents the "average"

------------------------------------------------------------------------

## Measures of Variation

1.  Range
2.  Variance
3.  Standard Deviation

------------------------------------------------------------------------

## Range

-   Minimum and maximum values
-   Example: 1, 3, 4, 5, 5, 6, 7, 8, 9, 24
-   Range: 1 to 24

------------------------------------------------------------------------

## Variance

$variance = \frac{\text{Sum of squared difference scores}}{\text{Number of Scores}}$

-   Measures spread of data around the mean

------------------------------------------------------------------------

## Standard Deviation

$\text{standard deviation} = \sqrt{\frac{\sum_{i}^{n}({x_{i}-\bar{x})^2}}{N}}$

-   Square root of variance
-   In same units as original data

------------------------------------------------------------------------

## Using Descriptive Statistics

-   Reduce large datasets to summary statistics
-   Combine with graphical representations
-   Be aware of limitations (e.g., Anscombe's Quartet)

------------------------------------------------------------------------

## Anscombe's Quartet

```{r}
#| echo: false
library(ggplot2)
library(data.table)

ac <- fread("materials/data/anscombe.txt")
ac <- as.data.frame(ac)

ac_long <- data.frame(
  x = c(ac[,1], ac[,3], ac[,5], ac[,7]),
  y = c(ac[,2], ac[,4], ac[,6], ac[,8]),
  quartet = as.factor(rep(1:4, each=11))
)

ggplot(ac_long, aes(x=x, y=y, color=quartet)) +
  geom_point() +
  theme_classic() +
  facet_wrap(~quartet)
```

-   Same descriptive statistics, different patterns

------------------------------------------------------------------------

## Remember

-   Always look at your data
-   Combine descriptive statistics with visualizations
-   Be aware of potential hidden patterns